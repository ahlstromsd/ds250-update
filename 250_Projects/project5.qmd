---
title: "Client Report - The War with Star Wars"
subtitle: "Course DS 250"
author: "Sydney Ahlstrom"
format:
  html:
    self-contained: true
    page-layout: full
    title-block-banner: true
    toc: true
    toc-depth: 3
    toc-location: body
    number-sections: false
    html-math-method: katex
    code-fold: true
    code-summary: "Show the code"
    code-overflow: wrap
    code-copy: hover
    code-tools:
        source: false
        toggle: true
        caption: See code
execute: 
  warning: false
    
---

```{python}
import pandas as pd 
import numpy as np
from lets_plot import *
# add the additional libraries you need to import for ML here

LetsPlot.setup_html(isolated_frame=True)
```


```{python}
# Learn morea about Code Cells: https://quarto.org/docs/reference/cells/cells-jupyter.html

# Include and execute your code here

# import your data here using pandas and the URL
url = "https://github.com/fivethirtyeight/data/raw/master/star-wars-survey/StarWars.csv"
df = pd.read_csv(url, encoding="ISO-8859-1")


print(df.columns.tolist())

```

## Elevator pitch
_A SHORT (2-3 SENTENCES) PARAGRAPH THAT `DESCRIBES KEY INSIGHTS` TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS._ (Note: this is not a summary of the project, but a summary of the results.)

_A Client has requested this analysis and this is your one shot of what you would say to your boss in a 2 min elevator ride before he takes your report and hands it to the client._

## QUESTION|TASK 1

__Shorten the column names and clean them up for easier use with pandas.__ Provide a table or list that exemplifies how you fixed the names. 

_type your results and analysis here_

```{python}
# Load original column names
original_columns = df.columns.tolist()

# Define manual renames
manual_renames = {
    'respondentid': 'id',
    'which_episode_s': 'seen_ep_',
    'which_of_the_following_characters_do_you_view_favorably': 'char_fav_',
    'do_you_consider_yourself_to_be_a_fan_of_the_star_wars_film_series': 'fan'
}
protected_names = [
    'age',
    'household_income',
    'education',
    'location',
]

# Clean column names
cleaned_columns = []
for col in df.columns:
    original_col = col  # preserve original

    # Strip and lowercase
    clean = col.strip().lower()

    # Preserve protected columns exactly as-is
    if any(protected in clean for protected in protected_names):
        cleaned_columns.append(clean)
        continue

    # Clean up
    clean = clean.replace(' ', '_').replace('-', '_').replace('(', '').replace(')', '').replace('?', '')
    clean = clean.replace(':', '').replace('/', '_')
    clean = clean.replace('__', '_')  # remove any double underscores

    # Apply manual renames
    for key in manual_renames:
        if clean.startswith(key):
            clean = clean.replace(key, manual_renames[key])

    cleaned_columns.append(clean)

# Apply cleaned names
df.columns = cleaned_columns

# Show all current column names
print("\nCleaned column names:")
print(df.columns.tolist())

# Side-by-side table of changes
name_table = pd.DataFrame({
    "Original Name": original_columns,
    "Cleaned Name": df.columns
})
name_table.head(20)
```


## QUESTION|TASK 2

__Clean and format the data so that it can be used in a machine learning model.__ As you format the data, you should complete each item listed below. In your final report provide example(s) of the reformatted data with a short description of the changes made.  
    a. Filter the dataset to respondents that have seen at least one film  
    a. Create a new column that converts the age ranges to a single number. Drop the age range categorical column  
    a. Create a new column that converts the education groupings to a single number. Drop the school categorical column  
    a. Create a new column that converts the income ranges to a single number. Drop the income range categorical column  
    a. Create your target (also known as “y” or “label”) column based on the new income range column  
    a. One-hot encode all remaining categorical columns   

_type your results and analysis here_

```{python}
seen_cols = [col for col in df.columns if col.startswith("seen_ep_")]

df_filtered = df[df[seen_cols].notna().any(axis=1)].copy()
print(f"Filtered from {len(df)} to {len(df_filtered)} rows")
```

```{python}
# Check the name
print(df_filtered.columns.tolist())

df_filtered[['age']].dropna().value_counts()

# Map age ranges
age_map = {
    '18-29': 24,
    '30-44': 37,
    '45-60': 52,
    '> 60': 65
}

df_filtered['age_num'] = df_filtered['age'].map(age_map)
df_filtered.drop(columns=['age'], inplace=True)
```

```{python}
# Check values
df_filtered['education'].value_counts()

# Map to levels
edu_map = {
    'Less than high school degree': 10,
    'High school degree': 12,
    'Some college or Associate degree': 14,
    'Bachelor degree': 16,
    'Graduate degree': 18
}

df_filtered['education_num'] = df_filtered['education'].map(edu_map)
df_filtered.drop(columns=['education'], inplace=True)
```

```{python}
# Check values
df_filtered['household_income'].value_counts()

# Map to dollar values
income_map = {
    '$0 - $24,999': 12500,
    '$25,000 - $49,999': 37500,
    '$50,000 - $99,999': 75000,
    '$100,000 - $149,999': 125000,
    '$150,000+': 175000,
    'Prefer not to answer': np.nan
}

df_filtered['income_num'] = df_filtered['household_income'].map(income_map)
df_filtered.drop(columns=['household_income'], inplace=True)
```

```{python}
# Target variable: 1 if income > 50k, 0 otherwise
df_filtered['target_income_over_50k'] = (df_filtered['income_num'] > 50000).astype(int)
```

```{python}
# Check data types to find categoricals
categoricals = df_filtered.select_dtypes(include='object').columns.tolist()

# One-hot encode all remaining categoricals
df_encoded = pd.get_dummies(df_filtered, columns=categoricals, drop_first=True)

# Show final shape and sample
print(df_encoded.shape)
df_encoded.head()
```

## QUESTION|TASK 3

__Validate that the data provided on GitHub lines up with the article by recreating 2 of the visuals from the article.__  

_type your results and analysis here_

```{python}
# Column with movie selections
seen_col = 'which_of_the_following_star_wars_films_have_you_seen_please_select_all_that_apply.'

# Fill NaNs with empty string to safely split
df[seen_col] = df[seen_col].fillna("")

# Define mapping from full movie title to short label
movie_map = {
    "Star Wars: Episode I  The Phantom Menace": "Ep I",
    "Star Wars: Episode II  Attack of the Clones": "Ep II",
    "Star Wars: Episode III  Revenge of the Sith": "Ep III",
    "Star Wars: Episode IV  A New Hope": "Ep IV",
    "Star Wars: Episode V The Empire Strikes Back": "Ep V",
    "Star Wars: Episode VI Return of the Jedi": "Ep VI"
}

# Create new columns for each movie
for full_title, short_label in movie_map.items():
    df[short_label] = df[seen_col].apply(lambda x: full_title in x)

# Calculate percentage seen for each movie
seen_percent = df[[*movie_map.values()]].mean() * 100
print("Seen percent:\n", seen_percent)

# Plot
ggplot() + \
    geom_bar(aes(x=seen_percent.index, y=seen_percent.values), stat='identity', fill="#1f77b4") + \
    ggtitle("Percentage of Respondents Who Have Seen Each Star Wars Movie") + \
    xlab("Movie Episode") + ylab("Percentage Seen") + \
    theme(axis_text_x=element_text(angle=45, hjust=1))
```

```{python}
# Get favorability columns
favor_cols = [col for col in df.columns if col.startswith("char_fav_")]

# Calculate % favorability (count non-NA "Very favorably" or "Somewhat favorably")
def favorable(val):
    return str(val).strip().lower() in ['very favorably', 'somewhat favorably']

favor_percent = {}
for col in favor_cols:
    char = col.replace('char_fav_', '').replace('_', ' ').title()
    percent = df[col].apply(favorable).mean() * 100
    favor_percent[char] = percent

# Create a sorted dataframe
favor_df = pd.DataFrame.from_dict(favor_percent, orient='index', columns=['favorability']).sort_values(by='favorability', ascending=False).reset_index()
favor_df.columns = ['character', 'favorability']

# Plot
ggplot(favor_df, aes(x='reorder(character, -favorability)', y='favorability')) + \
    geom_bar(stat='identity', fill='#ff7f0e') + \
    ggtitle("Favorability of Major Star Wars Characters") + \
    xlab("Character") + ylab("Percent Favorable") + \
    theme(axis_text_x=element_text(angle=45, hjust=1))
```

## QUESTION|TASK 4

__Build a machine learning model that predicts whether a person makes more than $50k. Describe your model and report the accuracy.__ 

_type your results and analysis here_

```{python}
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

# Define X and y
X = df_encoded.drop(columns=['income_num', 'target_income_over_50k'])
y = df_encoded['target_income_over_50k']

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the model
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

# Predict and evaluate
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

print(f"Model Accuracy: {accuracy:.2%}")
print("\nClassification Report:\n", classification_report(y_test, y_pred))

print("df_encoded shape:", df_encoded.shape)
print(df_encoded.columns[:10])  # check some columns exist
print(df_encoded['target_income_over_50k'].value_counts())  # check if target exists
```

---

## STRETCH QUESTION|TASK 1

__Build a machine learning model that predicts whether a person makes more than $50k. With accuracy of at least 65%. Describe your model and report the accuracy.__

_type your results and analysis here_

```{python}
# Include and execute your code here


```


## STRETCH QUESTION|TASK 2

__Validate the data provided on GitHub lines up with the article by recreating a 3rd visual from the article.__

_type your results and analysis here_

```{python}
# Include and execute your code here


```


## STRETCH QUESTION|TASK 3

__Create a new column that converts the location groupings to a single number. Drop the location categorical column.__  

_type your results and analysis here_

```{python}
# Include and execute your code here


```

---
